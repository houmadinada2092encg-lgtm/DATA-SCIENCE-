# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1a4FC0nX_K5t_wjninTXCHeQFlkiMQDjN
"""

#Importing Libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

#For ignoring warning
import warnings
warnings.filterwarnings("ignore")

df=pd.read_csv('/content/drive/MyDrive/Préparation examen/PREDICTION /ANALYSE /Business_sales_EDA.csv')
df



"""# Task
Correctly parse the "Product ID;Product Position;Promotion;Product Category;Seasonal;Sales Volume;brand;url;name;description;price;currency;terms;section;season;material;origin" column of the `df` DataFrame into individual columns, then proceed with the comprehensive predictive analysis plan which includes exploratory data analysis, feature engineering, data splitting, training and evaluating linear, polynomial, decision tree, random forest, and support vector regression models, and finally comparing their performances and summarizing the findings.

## Chargement et Prétraitement des Données

### Subtask:
Charger le jeu de données et effectuer les étapes de nettoyage et de prétraitement nécessaires, y compris la gestion des valeurs manquantes, la conversion des types de données et l'encodage des variables catégorielles si nécessaire. La colonne 'Product ID;Product Position;Promotion;Product Category;Seasonal;Sales Volume;brand;url;name;description;price;currency;terms;section;season;material;origin' doit être correctement parsée en colonnes séparées.

**Reasoning**:
The existing DataFrame `df` has a single column that contains all the data separated by semicolons. I need to parse this column into multiple distinct columns, following the provided instructions.
"""

column_names_string = 'Product ID;Product Position;Promotion;Product Category;Seasonal;Sales Volume;brand;url;name;description;price;currency;terms;section;season;material;origin'
new_column_names = column_names_string.split(';')

# Split the single column into new columns
split_data = df.iloc[:, 0].str.split(';', expand=True)

# Assign the new column names
split_data.columns = new_column_names

# Concatenate the new DataFrame with the original (optional, but good practice if other columns existed)
df = pd.concat([df.drop(df.columns[0], axis=1), split_data], axis=1)


print("DataFrame after parsing the single column:")
df.head()

"""**Reasoning**:
Now that the single column has been parsed into multiple columns, the next step is to examine the data types of each column and check for any missing values. This is a crucial step in data cleaning and will inform subsequent preprocessing decisions.


"""

print("Data types of each column:")
print(df.info())
print("\nMissing values in each column:")
print(df.isnull().sum())

"""**Reasoning**:
Based on the `df.info()` output, 'Sales Volume' and 'price' columns are currently of 'object' type. These columns represent numerical values and need to be converted to appropriate numeric data types (e.g., integer for 'Sales Volume' and float for 'price') to enable numerical operations and analysis. It's crucial to handle any potential errors during conversion, such as non-numeric characters, by coercing them to NaN and then handling these NaNs if they appear.


"""

df['Sales Volume'] = pd.to_numeric(df['Sales Volume'], errors='coerce')
df['price'] = pd.to_numeric(df['price'], errors='coerce')

print("Data types after numeric conversion:")
print(df.info())
print("\nMissing values after numeric conversion:")
print(df.isnull().sum())

"""**Reasoning**:
Now that numerical columns have been correctly converted, the next step in data preprocessing, as per the subtask, is to encode categorical variables. Before encoding, it's good practice to identify all categorical columns and examine their unique values to understand their cardinality, which will guide the choice of encoding method.


"""

print("Unique values and counts for categorical columns:")
for column in df.select_dtypes(include='object').columns:
    print(f"\nColumn '{column}':")
    print(df[column].value_counts())

"""**Reasoning**:
Based on the analysis of unique values, several categorical columns are suitable for one-hot encoding due to their low to medium cardinality. Columns with very high cardinality (like 'Product ID', 'url', 'name', 'description') or single unique values ('Product Category', 'brand', 'currency') are not useful for direct encoding or provide no predictive power, so they will be dropped. I will encode the remaining categorical features.


"""

columns_to_encode = ['Product Position', 'Promotion', 'Seasonal', 'terms', 'section', 'season', 'material', 'origin']
columns_to_drop = ['Product ID', 'Product Category', 'brand', 'url', 'name', 'description', 'currency']

# Drop identified non-useful columns
df = df.drop(columns=columns_to_drop)

# Apply one-hot encoding to the selected categorical columns
df = pd.get_dummies(df, columns=columns_to_encode, drop_first=True)

print("DataFrame after dropping non-useful columns and one-hot encoding:")
print(df.head())
print("\nDataFrame info after encoding:")
print(df.info())

"""## Analyse Exploratoire des Données (EDA)

### Subtask:
Réaliser une analyse exploratoire pour comprendre la distribution des variables, les corrélations entre elles, et identifier les relations potentielles avec la variable cible 'Sales Volume'. Ceci inclura des visualisations clés.

**Reasoning**:
The first instruction of the subtask is to display descriptive statistics for the numerical columns. This is a fundamental step in EDA to understand the central tendency, dispersion, and shape of the numerical features.
"""

print("Descriptive statistics for 'Sales Volume' and 'price':\n")
print(df[['Sales Volume', 'price']].describe())

plt.figure(figsize=(10, 6))
sns.histplot(df['Sales Volume'], kde=True, color='skyblue')
plt.title('Distribution of Sales Volume')
plt.xlabel('Sales Volume')
plt.ylabel('Frequency')
plt.show()

plt.figure(figsize=(10, 6))
sns.scatterplot(x='price', y='Sales Volume', data=df, alpha=0.6)
plt.title('Sales Volume vs. Price')
plt.xlabel('Price')
plt.ylabel('Sales Volume')
plt.show()

# Calculate correlations with 'Sales Volume'
correlations = df.corr(numeric_only=True)['Sales Volume'].sort_values(ascending=False)
print("\nCorrelations with 'Sales Volume':\n")
print(correlations)

# Select top N most correlated features (excluding 'Sales Volume' itself) for heatmap visualization
top_n = 10
top_correlated_features = correlations.drop('Sales Volume').head(top_n).index.tolist()
# Add 'Sales Volume' back to the list for the heatmap
features_for_heatmap = ['Sales Volume'] + top_correlated_features

plt.figure(figsize=(12, 8))
sns.heatmap(df[features_for_heatmap].corr(), annot=True, cmap='coolwarm', fmt=".2f")
plt.title(f'Top {top_n} Features Correlation with Sales Volume')
plt.show()

# Boxplots for selected categorical variables against 'Sales Volume'
selected_categorical_cols = ['Product Position_End-cap', 'Promotion_Yes', 'Seasonal_Yes', 'section_WOMAN']

plt.figure(figsize=(15, 10))
for i, col in enumerate(selected_categorical_cols):
    plt.subplot(2, 2, i + 1) # Adjust subplot grid based on number of columns
    sns.boxplot(x=col, y='Sales Volume', data=df)
    plt.title(f'Sales Volume by {col}')
    plt.xlabel(col)
    plt.ylabel('Sales Volume')
plt.tight_layout()
plt.show()

"""## Sélection et Ingénierie des Caractéristiques

### Subtask:
Sélectionner les caractéristiques pertinentes pour la modélisation prédictive et, si nécessaire, créer de nouvelles caractéristiques à partir des données existantes (ingénierie de caractéristiques). Préparer les données (mise à l'échelle, etc.) pour l'entraînement des modèles de régression.

**Reasoning**:
The subtask requires defining the target variable and features, and then scaling the features. I will first separate 'Sales Volume' as the target variable `y` and the remaining columns as features `X`. Then, I will use `StandardScaler` to scale the features in `X` to prepare them for model training, storing the result in `X_scaled`.
"""

from sklearn.preprocessing import StandardScaler

# 1. Définir la variable cible 'Sales Volume' comme y et toutes les autres colonnes comme les caractéristiques X
y = df['Sales Volume']
X = df.drop('Sales Volume', axis=1)

# 2. Importer StandardScaler de sklearn.preprocessing (done in the first line)
# 3. Initialiser un objet StandardScaler
scaler = StandardScaler()

# 4. Appliquer le scaler pour transformer les caractéristiques X et stocker le résultat dans X_scaled
X_scaled = scaler.fit_transform(X)

print("Shape of X:", X.shape)
print("Shape of y:", y.shape)
print("Shape of X_scaled:", X_scaled.shape)
print("\nFirst 5 rows of scaled features (X_scaled):")
print(X_scaled[:5])

"""**Reasoning**:
The next logical step after scaling the features is to split the data into training and testing sets. This is a crucial step to prepare the data for training and evaluating the regression models, as specified in the overall predictive analysis plan.


"""

from sklearn.model_selection import train_test_split

# Split the scaled data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

print("Shape of X_train:", X_train.shape)
print("Shape of X_test:", X_test.shape)
print("Shape of y_train:", y_train.shape)
print("Shape of y_test:", y_test.shape)

"""## Modélisation de Régression Linéaire

### Subtask:
Construire un modèle de régression linéaire, l'entraîner sur les données d'entraînement et évaluer ses performances sur l'ensemble de test. Inclure des commentaires en français sur les résultats et un graphique des valeurs prédites vs réelles, ainsi que les résidus.

**Reasoning**:
The next step is to import the necessary `LinearRegression` model, initialize it, train it on the scaled training data, and then make predictions on the scaled test data.
"""

from sklearn.linear_model import LinearRegression

# Initialize the Linear Regression model
linear_model = LinearRegression()

# Train the model on the training data
linear_model.fit(X_train, y_train)

# Predict 'Sales Volume' on the test set
y_pred_lr = linear_model.predict(X_test)

print("Linear Regression model trained and predictions made.")

"""**Reasoning**:
Now that the linear regression model has been trained and predictions made, the next step is to evaluate its performance using key regression metrics: Mean Absolute Error (MAE), Mean Squared Error (MSE), and R-squared (R²). This will fulfill parts 5 and 6 of the subtask instructions.


"""

from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# Calculate evaluation metrics
mae_lr = mean_absolute_error(y_test, y_pred_lr)
mse_lr = mean_squared_error(y_test, y_pred_lr)
r2_lr = r2_score(y_test, y_pred_lr)

print(f"\n--- Évaluation du Modèle de Régression Linéaire ---")
print(f"MAE (Mean Absolute Error): {mae_lr:.2f}")
print(f"MSE (Mean Squared Error): {mse_lr:.2f}")
print(f"R² (Coefficient de Détermination): {r2_lr:.2f}")

print("\nCommentaires sur les résultats:\n")
print("Le modèle de régression linéaire a été entraîné pour prédire le volume des ventes.\n")
print(f"- Le MAE de {mae_lr:.2f} indique que, en moyenne, les prédictions du modèle s'écartent des ventes réelles de {mae_lr:.2f} unités. C'est une mesure de l'erreur absolue moyenne.")
print(f"- Le MSE de {mse_lr:.2f} pénalise les erreurs plus importantes, ce qui peut donner une idée de la présence d'outliers significatifs. C'est la moyenne des carrés des erreurs.")
print(f"- Le coefficient R² de {r2_lr:.2f} signifie que le modèle explique {r2_lr*100:.2f}% de la variance dans le volume des ventes. Un R² plus élevé indique une meilleure adéquation du modèle aux données. Dans ce cas, le modèle explique une part substantielle de la variance, ce qui est un bon indicateur.")

"""**Reasoning**:
Now that the model has been evaluated, the next step is to visualize the actual vs. predicted values and the residuals, as per points 7, 8 and 9 of the subtask. This will provide a visual assessment of the model's performance and help identify any patterns in the errors.


"""

import matplotlib.pyplot as plt
import seaborn as sns

# 7. Créer un graphique comparant les valeurs réelles et les valeurs prédites
plt.figure(figsize=(10, 6))
sns.scatterplot(x=y_test, y=y_pred_lr, alpha=0.6)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2) # Ligne y=x
plt.title('Régression Linéaire: Valeurs Réelles vs. Prédites')
plt.xlabel('Valeurs Réelles (y_test)')
plt.ylabel('Valeurs Prédites (y_pred_lr)')
plt.grid(True)
plt.show()

# 8. Calculer les résidus
residuals_lr = y_test - y_pred_lr

# 9. Créer un histogramme des résidus
plt.figure(figsize=(10, 6))
sns.histplot(residuals_lr, kde=True, color='purple')
plt.title('Régression Linéaire: Distribution des Résidus')
plt.xlabel('Résidus')
plt.ylabel('Fréquence')
plt.grid(True)
plt.show()

# Créer un nuage de points des résidus contre les valeurs prédites
plt.figure(figsize=(10, 6))
sns.scatterplot(x=y_pred_lr, y=residuals_lr, alpha=0.6, color='green')
plt.axhline(y=0, color='r', linestyle='--', lw=2)
plt.title('Régression Linéaire: Résidus vs. Valeurs Prédites')
plt.xlabel('Valeurs Prédites (y_pred_lr)')
plt.ylabel('Résidus')
plt.grid(True)
plt.show()

"""## Modélisation de Régression Polynomiale

### Subtask:
Construire un modèle de régression polynomiale, l'entraîner sur les données d'entraînement et évaluer ses performances sur l'ensemble de test. Inclure des commentaires en français sur les résultats et un graphique des valeurs prédites vs réelles.

**Reasoning**:
I need to import `PolynomialFeatures` from `sklearn.preprocessing` and `LinearRegression` from `sklearn.linear_model` to build the polynomial regression model, then transform the training and testing data into polynomial features, and finally train the linear regression model on these transformed features.
"""

from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression

# 2. Créer un objet PolynomialFeatures avec un degré approprié (degree=2)
poly_features = PolynomialFeatures(degree=2)

# 3. Transformer les ensembles d'entraînement et de test en caractéristiques polynomiales
X_poly_train = poly_features.fit_transform(X_train)
X_poly_test = poly_features.transform(X_test)

# 4. Initialiser un modèle de LinearRegression
poly_model = LinearRegression()

# 5. Entraîner le modèle de régression linéaire sur les caractéristiques polynomiales d'entraînement
poly_model.fit(X_poly_train, y_train)

# 6. Utiliser le modèle entraîné pour prédire le volume des ventes sur l'ensemble de test transformé
y_pred_poly = poly_model.predict(X_poly_test)

print("Polynomial Regression model trained and predictions made.")

"""**Reasoning**:
Now that the polynomial regression model has been trained and predictions made, the next step is to evaluate its performance using key regression metrics: Mean Absolute Error (MAE), Mean Squared Error (MSE), and R-squared (R²). This will fulfill parts 7 and 8 of the subtask instructions.


"""

from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# Calculate evaluation metrics
mae_poly = mean_absolute_error(y_test, y_pred_poly)
mse_poly = mean_squared_error(y_test, y_pred_poly)
r2_poly = r2_score(y_test, y_pred_poly)

print(f"\n--- Évaluation du Modèle de Régression Polynomiale (Degré 2) ---")
print(f"MAE (Mean Absolute Error): {mae_poly:.2f}")
print(f"MSE (Mean Squared Error): {mse_poly:.2f}")
print(f"R² (Coefficient de Détermination): {r2_poly:.2f}")

print("\nCommentaires sur les résultats:\n")
print("Le modèle de régression polynomiale de degré 2 a été entraîné pour prédire le volume des ventes.\n")
print(f"- Le MAE de {mae_poly:.2f} indique que les prédictions du modèle s'écartent en moyenne de {mae_poly:.2f} unités des ventes réelles.")
print(f"- Le MSE de {mse_poly:.2f} est une mesure de l'erreur quadratique moyenne.")
print(f"- Le coefficient R² de {r2_poly:.2f} signifie que ce modèle explique {r2_poly*100:.2f}% de la variance dans le volume des ventes.")
print("\nComparaison avec le modèle linéaire précédent:\n")
print(f"Le modèle de régression linéaire précédent avait un R² de {r2_lr:.2f}. Le modèle polynomiale avec un R² de {r2_poly:.2f} "
      f"montre une amélioration {'significative' if r2_poly > r2_lr else 'non significative' if r2_poly == r2_lr else 'ou une légère dégradation'} de la performance, "
      f"ce qui suggère que des relations non linéaires entre les caractéristiques et le volume des ventes peuvent exister et être mieux capturées par ce modèle.")

"""**Reasoning**:
Now that the polynomial regression model has been evaluated, the next step is to create a scatter plot comparing the actual (`y_test`) and predicted (`y_pred_poly`) values, and include a diagonal line (y=x) as a reference, as per point 9 of the subtask instructions.


"""

import matplotlib.pyplot as plt
import seaborn as sns

# 9. Créer un graphique de dispersion comparant les valeurs réelles aux valeurs prédites
plt.figure(figsize=(10, 6))
sns.scatterplot(x=y_test, y=y_pred_poly, alpha=0.6)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2) # Ligne y=x
plt.title('Régression Polynomiale: Valeurs Réelles vs. Prédites')
plt.xlabel('Valeurs Réelles (y_test)')
plt.ylabel('Valeurs Prédites (y_pred_poly)')
plt.grid(True)
plt.show()

"""## Modélisation de Régression par Arbres de Décision

### Subtask:
Construire un modèle de régression par arbres de décision, l'entraîner sur les données d'entraînement et évaluer ses performances sur l'ensemble de test. Inclure des commentaires en français sur les résultats et un graphique des valeurs prédites vs réelles.

**Reasoning**:
The next step is to import the `DecisionTreeRegressor` class, initialize it, train it on the `X_train` and `y_train` datasets, and then use it to predict `y_pred_dt` on the `X_test` dataset, as per the subtask instructions.
"""

from sklearn.tree import DecisionTreeRegressor

# 2. Initialize a DecisionTreeRegressor object
dt_model = DecisionTreeRegressor(random_state=42)

# 3. Train the model on the training data
dt_model.fit(X_train, y_train)

# 4. Use the trained model to predict sales volumes on the test set
y_pred_dt = dt_model.predict(X_test)

print("Decision Tree Regressor model trained and predictions made.")

"""**Reasoning**:
Now that the Decision Tree Regressor model has been trained and predictions made, the next step is to evaluate its performance using key regression metrics: Mean Absolute Error (MAE), Mean Squared Error (MSE), and R-squared (R²). This will fulfill parts 5, 6 and 7 of the subtask instructions, including comparing the results with previous models.


"""

from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# 5. Calculate evaluation metrics
mae_dt = mean_absolute_error(y_test, y_pred_dt)
mse_dt = mean_squared_error(y_test, y_pred_dt)
r2_dt = r2_score(y_test, y_pred_dt)

print(f"\n--- Évaluation du Modèle de Régression par Arbres de Décision ---")
print(f"MAE (Mean Absolute Error): {mae_dt:.2f}")
print(f"MSE (Mean Squared Error): {mse_dt:.2f}")
print(f"R² (Coefficient de Détermination): {r2_dt:.2f}")

print("\nCommentaires sur les résultats:\n")
print("Le modèle de régression par arbres de décision a été entraîné pour prédire le volume des ventes.\n")
print(f"- Le MAE de {mae_dt:.2f} indique que, en moyenne, les prédictions du modèle s'écartent des ventes réelles de {mae_dt:.2f} unités.")
print(f"- Le MSE de {mse_dt:.2f} est une mesure de l'erreur quadratique moyenne, pénalisant davantage les erreurs importantes.")
print(f"- Le coefficient R² de {r2_dt:.2f} signifie que ce modèle explique {r2_dt*100:.2f}% de la variance dans le volume des ventes.")

print("\nComparaison avec les modèles précédents:\n")
print(f"- Modèle Linéaire: MAE={mae_lr:.2f}, MSE={mse_lr:.2f}, R²={r2_lr:.2f}")
print(f"- Modèle Polynomial: MAE={mae_poly:.2f}, MSE={mse_poly:.2f}, R²={r2_poly:.2f}")
print(f"- Modèle Arbre de Décision: MAE={mae_dt:.2f}, MSE={mse_dt:.2f}, R²={r2_dt:.2f}")

if r2_dt > r2_lr and r2_dt > r2_poly:
    print("Le modèle d'arbre de décision semble surpasser les modèles linéaire et polynomial en termes de R².")
elif r2_dt == r2_lr and r2_dt == r2_poly:
    print("Le modèle d'arbre de décision a une performance similaire aux modèles linéaire et polynomial en termes de R².")
elif r2_dt > r2_lr and r2_dt < r2_poly:
    print("Le modèle d'arbre de décision a une performance meilleure que le modèle linéaire mais moins bonne que le polynomial.")
elif r2_dt < r2_lr and r2_dt > r2_poly:
    print("Le modèle d'arbre de décision a une performance moins bonne que le modèle linéaire mais meilleure que le polynomial.")
else:
    print("Le modèle d'arbre de décision a une performance inférieure aux modèles linéaire et polynomial.")

"""**Reasoning**:
Now that the Decision Tree Regressor model has been evaluated, the final step for this subtask is to visualize the actual vs. predicted values using a scatter plot, as requested in instruction #8 of the subtask.


"""

import matplotlib.pyplot as plt
import seaborn as sns

# 8. Créer un graphique de dispersion comparant les valeurs réelles aux valeurs prédites
plt.figure(figsize=(10, 6))
sns.scatterplot(x=y_test, y=y_pred_dt, alpha=0.6)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2) # Ligne y=x
plt.title('Régression par Arbres de Décision: Valeurs Réelles vs. Prédites')
plt.xlabel('Valeurs Réelles (y_test)')
plt.ylabel('Valeurs Prédites (y_pred_dt)')
plt.grid(True)
plt.show()

"""## Modélisation de Régression par Forêts Aléatoires

### Subtask:
Construire un modèle de régression par forêts aléatoires (Random Forest), l'entraîner sur les données d'entraînement et évaluer ses performances sur l'ensemble de test. Inclure des commentaires en français sur les résultats et un graphique des valeurs prédites vs réelles.

**Reasoning**:
The next step is to import the `RandomForestRegressor` class, initialize it, train it on the `X_train` and `y_train` datasets, and then use it to predict `y_pred_rf` on the `X_test` dataset, as per the subtask instructions.
"""

from sklearn.ensemble import RandomForestRegressor

# 2. Initialize a RandomForestRegressor object
rf_model = RandomForestRegressor(random_state=42)

# 3. Train the model on the training data
rf_model.fit(X_train, y_train)

# 4. Use the trained model to predict sales volumes on the test set
y_pred_rf = rf_model.predict(X_test)

print("Random Forest Regressor model trained and predictions made.")

"""**Reasoning**:
Now that the Random Forest Regressor model has been trained and predictions made, the next step is to evaluate its performance using key regression metrics: Mean Absolute Error (MAE), Mean Squared Error (MSE), and R-squared (R²). This will fulfill parts 5 and 6 of the subtask instructions, including comparing the results with previous models.


"""

from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# 5. Calculate evaluation metrics
mae_rf = mean_absolute_error(y_test, y_pred_rf)
mse_rf = mean_squared_error(y_test, y_pred_rf)
r2_rf = r2_score(y_test, y_pred_rf)

print(f"\n--- Évaluation du Modèle de Régression par Forêts Aléatoires ---")
print(f"MAE (Mean Absolute Error): {mae_rf:.2f}")
print(f"MSE (Mean Squared Error): {mse_rf:.2f}")
print(f"R² (Coefficient de Détermination): {r2_rf:.2f}")

print("\nCommentaires sur les résultats:\n")
print("Le modèle de régression par forêts aléatoires a été entraîné pour prédire le volume des ventes.\n")
print(f"- Le MAE de {mae_rf:.2f} indique que, en moyenne, les prédictions du modèle s'écartent des ventes réelles de {mae_rf:.2f} unités.")
print(f"- Le MSE de {mse_rf:.2f} est une mesure de l'erreur quadratique moyenne, pénalisant davantage les erreurs importantes.")
print(f"- Le coefficient R² de {r2_rf:.2f} signifie que ce modèle explique {r2_rf*100:.2f}% de la variance dans le volume des ventes.")

print("\nComparaison avec les modèles précédents:\n")
print(f"- Modèle Linéaire: MAE={mae_lr:.2f}, MSE={mse_lr:.2f}, R²={r2_lr:.2f}")
print(f"- Modèle Polynomial: MAE={mae_poly:.2f}, MSE={mse_poly:.2f}, R²={r2_poly:.2f}")
print(f"- Modèle Arbre de Décision: MAE={mae_dt:.2f}, MSE={mse_dt:.2f}, R²={r2_dt:.2f}")
print(f"- Modèle Forêt Aléatoire: MAE={mae_rf:.2f}, MSE={mse_rf:.2f}, R²={r2_rf:.2f}")

if r2_rf > r2_lr and r2_rf > r2_poly and r2_rf > r2_dt:
    print("Le modèle de forêt aléatoire semble surpasser tous les modèles précédents en termes de R².")
elif r2_rf == r2_lr and r2_rf == r2_poly and r2_rf == r2_dt:
    print("Le modèle de forêt aléatoire a une performance similaire aux modèles précédents en termes de R².")
elif r2_rf > r2_lr and r2_rf > r2_poly and r2_rf <= r2_dt:
    print("Le modèle de forêt aléatoire a une performance meilleure que les modèles linéaire et polynomial, mais similaire ou légèrement inférieure à l'arbre de décision.")
elif r2_rf <= r2_lr and r2_rf <= r2_poly and r2_rf <= r2_dt:
    print("Le modèle de forêt aléatoire a une performance inférieure à la plupart des modèles précédents.")
else:
    print("Le modèle de forêt aléatoire a une performance mixte par rapport aux modèles précédents.")

"""**Reasoning**:
Now that the Random Forest Regressor model has been evaluated, the final step for this subtask is to visualize the actual vs. predicted values using a scatter plot, as requested in instruction #7 of the subtask.


"""

import matplotlib.pyplot as plt
import seaborn as sns

# 7. Créer un graphique de dispersion comparant les valeurs réelles aux valeurs prédites
plt.figure(figsize=(10, 6))
sns.scatterplot(x=y_test, y=y_pred_rf, alpha=0.6)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2) # Ligne y=x
plt.title('Régression par Forêts Aléatoires: Valeurs Réelles vs. Prédites')
plt.xlabel('Valeurs Réelles (y_test)')
plt.ylabel('Valeurs Prédites (y_pred_rf)')
plt.grid(True)
plt.show()

"""## Modélisation de Régression par Vecteurs de Support (SVR)

### Subtask:
Construire un modèle de régression par vecteurs de support (SVR), l'entraîner sur les données d'entraînement et évaluer ses performances sur l'ensemble de test. Inclure des commentaires en français sur les résultats et un graphique des valeurs prédites vs réelles.

**Reasoning**:
The first step in implementing SVR is to import the `SVR` class from `sklearn.svm`, initialize the model, and then train it on the scaled training data. This will fulfill the first three instructions of the subtask.
"""

from sklearn.svm import SVR

# 2. Initialisez un objet SVR. Utilisation du noyau par défaut ('rbf').
# Pour des raisons de performance sur des grands datasets, nous commençons avec les hyperparamètres par défaut.
svr_model = SVR()

# 3. Entraînez le modèle SVR sur les données d'entraînement
svr_model.fit(X_train, y_train)

# 4. Utilisez le modèle entraîné pour prédire le volume des ventes sur l'ensemble de test
y_pred_svr = svr_model.predict(X_test)

print("SVR model trained and predictions made.")

"""**Reasoning**:
Now that the SVR model has been trained and predictions made, the next step is to evaluate its performance using key regression metrics: Mean Absolute Error (MAE), Mean Squared Error (MSE), and R-squared (R²). This will fulfill parts 5, 6, and 7 of the subtask instructions, including comparing the results with previous models.


"""

from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# 6. Calculate evaluation metrics
mae_svr = mean_absolute_error(y_test, y_pred_svr)
mse_svr = mean_squared_error(y_test, y_pred_svr)
r2_svr = r2_score(y_test, y_pred_svr)

print(f"\n--- Évaluation du Modèle de Régression par Vecteurs de Support (SVR) ---")
print(f"MAE (Mean Absolute Error): {mae_svr:.2f}")
print(f"MSE (Mean Squared Error): {mse_svr:.2f}")
print(f"R² (Coefficient de Détermination): {r2_svr:.2f}")

print("\nCommentaires sur les résultats:\n")
print("Le modèle de régression par vecteurs de support (SVR) a été entraîné pour prédire le volume des ventes.\n")
print(f"- Le MAE de {mae_svr:.2f} indique que, en moyenne, les prédictions du modèle s'écartent des ventes réelles de {mae_svr:.2f} unités.")
print(f"- Le MSE de {mse_svr:.2f} est une mesure de l'erreur quadratique moyenne, pénalisant davantage les erreurs importantes.")
print(f"- Le coefficient R² de {r2_svr:.2f} signifie que ce modèle explique {r2_svr*100:.2f}% de la variance dans le volume des ventes.")

print("\nComparaison avec les modèles précédents:\n")
print(f"- Modèle Linéaire: MAE={mae_lr:.2f}, MSE={mse_lr:.2f}, R²={r2_lr:.2f}")
print(f"- Modèle Polynomial: MAE={mae_poly:.2f}, MSE={mse_poly:.2f}, R²={r2_poly:.2f}")
print(f"- Modèle Arbre de Décision: MAE={mae_dt:.2f}, MSE={mse_dt:.2f}, R²={r2_dt:.2f}")
print(f"- Modèle Forêt Aléatoire: MAE={mae_rf:.2f}, MSE={mse_rf:.2f}, R²={r2_rf:.2f}")
print(f"- Modèle SVR: MAE={mae_svr:.2f}, MSE={mse_svr:.2f}, R²={r2_svr:.2f}")

# Dynamic comparison with previous models
max_r2 = max(r2_lr, r2_poly, r2_dt, r2_rf, r2_svr)

if r2_svr == max_r2:
    print("Le modèle SVR est le plus performant parmi tous les modèles évalués en termes de R².")
elif r2_svr > r2_lr and r2_svr > r2_poly and r2_svr > r2_dt and r2_svr > r2_rf:
    print("Le modèle SVR est le plus performant parmi tous les modèles évalués en termes de R².")
elif r2_svr >= r2_lr and r2_svr >= r2_poly and r2_svr >= r2_dt and r2_svr >= r2_rf:
    print("Le modèle SVR a une performance compétitive par rapport aux meilleurs modèles précédents en termes de R².")
else:
    print("Le modèle SVR a une performance inférieure à certains des modèles précédents.")

"""**Reasoning**:
Now that the SVR model has been evaluated, the final step for this subtask is to visualize the actual vs. predicted values using a scatter plot, and include a diagonal line (y=x) as a reference, as requested in instructions 8, 9, 10, and 11 of the subtask.


"""

import matplotlib.pyplot as plt
import seaborn as sns

# 9. Créez un graphique de dispersion comparant les valeurs réelles aux valeurs prédites
plt.figure(figsize=(10, 6))
sns.scatterplot(x=y_test, y=y_pred_svr, alpha=0.6)
# 10. Ajoutez une ligne diagonale (y=x) au graphique pour faciliter la comparaison visuelle
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2) # Ligne y=x
# 11. Donnez un titre approprié au graphique et des étiquettes aux axes
plt.title('Régression SVR: Valeurs Réelles vs. Prédites')
plt.xlabel('Valeurs Réelles (y_test)')
plt.ylabel('Valeurs Prédites (y_pred_svr)')
plt.grid(True)
plt.show()

"""## Comparaison des Modèles et Conclusion

### Subtask:
Comparer les performances de tous les modèles de régression construits en utilisant des métriques appropriées (R-carré, RMSE, MAE) et identifier le modèle le plus performant. Présenter une synthèse finale avec des commentaires en français sur les insights obtenus.

**Reasoning**:
To compare the models, I will first compile the evaluation metrics (MAE, MSE, R²) for all trained models into a structured format. A dictionary will be used for this purpose, where each key represents a model and its value is another dictionary containing its performance metrics.
"""

metrics_data = {
    'Linear Regression': {
        'MAE': mae_lr,
        'MSE': mse_lr,
        'R2': r2_lr
    },
    'Polynomial Regression': {
        'MAE': mae_poly,
        'MSE': mse_poly,
        'R2': r2_poly
    },
    'Decision Tree': {
        'MAE': mae_dt,
        'MSE': mse_dt,
        'R2': r2_dt
    },
    'Random Forest': {
        'MAE': mae_rf,
        'MSE': mse_rf,
        'R2': r2_rf
    },
    'SVR': {
        'MAE': mae_svr,
        'MSE': mse_svr,
        'R2': r2_svr
    }
}

print("Metrics data dictionary created.")

"""**Reasoning**:
Now that the metrics data is in a dictionary, I will convert it into a pandas DataFrame to facilitate easy comparison and display, fulfilling instruction #2 and #3 of the subtask.


"""

import pandas as pd

# Convert the metrics dictionary into a pandas DataFrame
metrics_df = pd.DataFrame(metrics_data).T.sort_values(by='R2', ascending=False)

print("DataFrame récapitulatif des performances des modèles:")
print(metrics_df)

"""### Analyse Comparative des Modèles et Conclusion

Après avoir entraâné et évalué cinq modèles de régression différents pour prédire le 'Sales Volume', voici une synthèse de leurs performances et les conclusions à en tirer.

**Tableau Récapitulatif des Performances des Modèles:**
```
                              MAE           MSE        R2
Polynomial Regression   59.442901   5769.499586  0.934336
Linear Regression       62.387248   6307.527647  0.928212
Random Forest           63.025403   6426.358324  0.926860
Decision Tree           82.478071  11054.027181  0.874191
SVR                    137.590030  32144.979641  0.634150
```

**Modèle le Plus Performant :**

Basé sur les métriques d'évaluation, le **modèle de Régression Polynomiale (Degré 2)** se démarque comme le plus performant. Il présente le R² le plus élevé (0.93), indiquant qu'il explique la plus grande proportion de la variance des 'Sales Volume'. De plus, il a le MAE (59.44) et le MSE (5769.50) les plus faibles, ce qui signifie que ses prédictions sont, en moyenne, les plus proches des valeurs réelles et qu'il gère le mieux les erreurs importantes.

**Comparaison Détaillée et Insights :**

1.  **Régression Polynomiale vs. Linéaire :** La régression polynomiale a légèrement surpassé la régression linéaire, suggérant la présence de relations non linéaires entre les caractéristiques et le volume des ventes qui ont été mieux capturées par les termes quadratiques. Les deux modèles sont très performants avec un R² d'environ 0.93.

2.  **Random Forest :** Le modèle Random Forest a également montré une excellente performance, très proche de la régression linéaire et polynomiale en termes de R² (0.93) et de MAE. Cela confirme que des modèles basés sur des arbres, bien que potentiellement plus complexes, peuvent bien gérer les données présentant des interactions complexes et non-linéaires.

3.  **Arbre de Décision :** Le modèle d'arbre de décision, bien que simple et interprétable, a montré une performance inférieure (R² de 0.87) par rapport à la régression polynomiale, linéaire et Random Forest. Cela peut étre dû à sa tendance au surapprentissage (overfitting) sur les données d'entraânement ou à sa sensibilité à de petites variations dans les données.

4.  **SVR (Support Vector Regressor) :** Le modèle SVR a affiché la performance la plus faible parmi tous les modèles évalués (R² de 0.63, MAE le plus élevé). Cela pourrait étre dû à plusieurs facteurs, y compris le choix des hyperparamètres (qui n'ont pas été optimisés ici) ou l'inadaptation du noyau par défaut ('rbf') à la structure spécifique de nos données. Les SVR peuvent également àtre très coûteux en calcul sur de grands ensembles de données.

**Insights Clés :**

*   **Importance des Promotions :** L'EDA a révélé une corrélation très forte entre 'Promotion_Yes' et 'Sales Volume' (0.89). Les modèles les plus performants ont réussi à capturer cette relation. L'utilisation d'une promotion a un impact positif et significatif sur les ventes.
*   **Saisonnalité et Position du Produit :** 'Seasonal_Yes' et 'section_WOMAN' (pour la catégorie femme) ont également montré des corrélations positives avec les ventes, bien que moins prononcées que les promotions. Cela suggère que les ventes sont influencées par les périodes saisonnières et la démographie cible.
*   **Impact du Prix :** La corrélation négative du 'price' (-0.34) avec 'Sales Volume' indique que, comme prévu, des prix plus élevés tendent à réduire le volume des ventes.
*   **Nécessité de Prétraitement :** L'importance de la conversion des types de données (object vers numérique) et de l'encodage des variables catégorielles a été confirmée, permettant aux modèles de traiter efficacement les données.

**Conclusion Finale :**

Le modèle de régression polynomiale de degré 2 offre le meilleur compromis entre la capacité à expliquer la variance des ventes et la précision des prédictions pour ce jeu de données. Les autres modèles tels que la régression linéaire et Random Forest sont également très compétitifs. Le choix final pourrait dépendre d'autres facteurs comme la complexité d'implémentation ou les exigences en matière d'interprétabilité. Pour une prédiction précise du volume des ventes, la régression polynomiale ou Random Forest seraient les choix privilégiés.

## Final Task

### Subtask:
Fournir un résumé de l'analyse prédictive détaillée, y compris la performance de chaque modèle de régression et les conclusions clés.

## Summary:

### Data Analysis Key Findings

*   **Data Preprocessing**:
    *   A critical initial step involved parsing a single concatenated column into 17 distinct columns.
    *   'Sales Volume' and 'price' columns were successfully converted to numerical types (`int64` and `float64` respectively).
    *   Irrelevant columns (e.g., 'Product ID', 'url', 'description') were dropped, and relevant categorical features (`Product Position`, `Promotion`, `Seasonal`, `terms`, `section`, `season`, `material`, `origin`) were one-hot encoded, resulting in a final dataset of 35 features.
*   **Exploratory Data Analysis (EDA)**:
    *   `Sales Volume` ranged from 518 to 1940, with a mean of approximately 1097. `price` ranged from 12 to 134.99, averaging around 41.95.
    *   A very strong positive correlation was observed between `Promotion_Yes` and `Sales Volume` (0.89).
    *   `price` showed a moderate negative correlation with `Sales Volume` (-0.34).
    *   Other features like `Seasonal_Yes` (0.25) and `section_WOMAN` (0.18) also showed positive correlations.
*   **Model Performance Comparison**:
    *   **Polynomial Regression (Degree 2)** emerged as the best-performing model with an R² of approximately 0.93, a Mean Absolute Error (MAE) of 59.44, and a Mean Squared Error (MSE) of 5769.50. This indicates it explains about 93.43% of the variance in sales volume.
    *   **Linear Regression** and **Random Forest** models also performed exceptionally well, both achieving an R² of around 0.93 and comparable MAE/MSE scores (Linear: MAE 62.39, MSE 6307.53; Random Forest: MAE 63.03, MSE 6426.36).
    *   The **Decision Tree** model showed a lower performance with an R² of 0.87, MAE of 82.48, and MSE of 11054.03.
    *   The **Support Vector Regressor (SVR)** model, without hyperparameter tuning, exhibited the lowest performance, with an R² of 0.63, MAE of 137.59, and MSE of 32144.98.

### Insights or Next Steps

*   The strong performance of Polynomial Regression and Random Forest models suggests that sales volume prediction can be highly accurate (explaining over 93% of variance). Given the comparable performance, the choice between them might depend on interpretability (simpler for Polynomial) versus robustness to outliers and non-linearities (stronger for Random Forest).
*   Further hyperparameter tuning for the Polynomial Regression, Random Forest, and especially SVR models could potentially yield even better results. For SVR, exploring different kernels and C/gamma values is recommended. Additionally, investigating feature importance from the Random Forest model could provide deeper business insights into which factors are most critical for sales.
"""